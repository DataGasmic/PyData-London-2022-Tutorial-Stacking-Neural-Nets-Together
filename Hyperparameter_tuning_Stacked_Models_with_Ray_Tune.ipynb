{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter tuning Stacked Models with Ray Tune ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxlCa-GN5A0h",
        "outputId": "91778ec7-d8c6-4b72-8a4e-b91fbcb1ed8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ray\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 236 kB/s \n",
            "\u001b[?25hRequirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 38.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.17.3)\n",
            "Collecting virtualenv\n",
            "  Downloading virtualenv-20.14.1-py2.py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 36.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray) (21.4.0)\n",
            "Collecting aiosignal\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (4.3.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.21.6)\n",
            "Collecting frozenlist\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.1)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<=1.43.0,>=1.28.1->ray) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.11.4)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (5.7.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema->ray) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 53.8 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: platformdirs, frozenlist, distlib, virtualenv, grpcio, aiosignal, ray\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "Successfully installed aiosignal-1.2.0 distlib-0.3.4 frozenlist-1.3.0 grpcio-1.43.0 platformdirs-2.5.2 ray-1.13.0 virtualenv-20.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Fetch and Processing Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# For the stacked models\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Dense,Flatten,Input,concatenate, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adadelta, Adam, RMSprop\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Distributed Training\n",
        "from ray import tune\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from ray.tune.suggest import ConcurrencyLimiter\n",
        "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
        "from ray.tune.integration.keras import TuneReportCallback\n",
        "# Parameter Optimisation\n",
        "import hyperopt\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
        "# Metrics\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error ,mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "jy8kX8OnVIvY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()"
      ],
      "metadata": {
        "id": "tHqkbukZVJQu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = housing['data']\n",
        "y = housing['target']"
      ],
      "metadata": {
        "id": "lzp3_gB3sugg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train , y_test = train_test_split(X, y , train_size = 0.7, random_state = 42)"
      ],
      "metadata": {
        "id": "5tvJGUu9YDK_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's tune 2 neural networks together"
      ],
      "metadata": {
        "id": "5nhCr5-PYJNy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "space = {  # Network 1\n",
        "            \"m1_kernel_initializer1\":hp.choice('kernel_initializer_m1_1',['glorot_uniform','he_normal']),\n",
        "            \"m1_bias_initializer1\":hp.choice('bias_initializer_m1_1',['ones','glorot_uniform']),\n",
        "            \"m1_kernel_initializer2\":hp.choice('kernel_initializer_m1_2',['glorot_normal','he_uniform']),\n",
        "            \"m1_bias_initializer2\":hp.choice('bias_initializer_m1_2',['zeros','ones']),\n",
        "            'm1_dropout': hp.choice('dropout1', [0, 0.25, 0.5]),\n",
        "    \n",
        "          # Network 2\n",
        "            \"m2_kernel_initializer1\":hp.choice('kernel_initializer_m2',['glorot_normal','he_uniform']),\n",
        "            \"m2_bias_initializer1\":hp.choice('bias_initializer_m2',['zeros','ones']),\n",
        "            \"batch_normalisation\" : hp.choice(\"batch_normalisation\",[None,True]),\n",
        "            'm2_dropout': hp.choice('dropout2', [0, 0.25, 0.5]),\n",
        "            \n",
        "          # Stacked \n",
        "            \"lr\": hp.choice(\"lr\", [1e-2, 1e-3, 1e-4, 1e-5]),\n",
        "            'epochs' :  hp.choice('epochs',[10,15,20,25]),\n",
        "            'batch_size': hp.choice('batch_size', [16,32,64,128])\n",
        "        }"
      ],
      "metadata": {
        "id": "aak2UO0uLXB9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyper_tuner(space):\n",
        "\n",
        "  # Network 1\n",
        "  network_1 = Sequential()\n",
        "  network_1.add(Dense(units = 4, input_dim=X_train.shape[1] ,\n",
        "                      activation='relu', bias_initializer = space['m1_bias_initializer1'],\n",
        "                      kernel_initializer=space['m1_kernel_initializer1']))\n",
        "  \n",
        "  network_1.add(Dense(units = 4, activation='relu',\n",
        "                      bias_initializer = space['m1_bias_initializer2'],\n",
        "                      kernel_initializer = space['m1_kernel_initializer2']))\n",
        "  network_1.add(Dropout(space['m1_dropout']))\n",
        "  network_1.add(Dense(units = 4, activation='relu'))\n",
        "  network_1.add(Dense(units = 4, activation='relu'))\n",
        "  \n",
        "  # Network 2\n",
        "  network_2 = Sequential()\n",
        "  network_2.add(Dense(units = 16, input_dim=X_train.shape[1] , activation='relu',\n",
        "                      bias_initializer = space['m2_bias_initializer1'],\n",
        "                      kernel_initializer=space['m2_kernel_initializer1']))\n",
        "  if space['batch_normalisation']:\n",
        "        network_2.add(BatchNormalization())\n",
        "  network_2.add(Dense(units = 16, activation='relu'))\n",
        "  network_2.add(Dropout(space['m2_dropout']))\n",
        "  \n",
        "  # Stacking the Networks\n",
        "\n",
        "  combinedInput = concatenate([network_1.output, network_2.output])\n",
        "  x = Dense(1, activation=\"linear\")(combinedInput)\n",
        "  model = Model(inputs=[network_1.input, network_2.input], outputs=x)\n",
        "  adam = Adam(learning_rate=space['lr']) \n",
        "  model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mean_squared_error'])\n",
        "  model.fit( x=[X_train, X_train],\n",
        "          y=y_train,\n",
        "          validation_split = 0.2,\n",
        "          epochs=space['epochs'], batch_size=space['batch_size'], verbose = 0,\n",
        "          callbacks=[TuneReportCallback({'mean_se':'mean_squared_error'})])\n",
        "  "
      ],
      "metadata": {
        "id": "jgP5mPd_MD8W"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To return the model after hyperparameters have been selected\n",
        "def tuned_dnn(space):\n",
        "\n",
        "  # Network 1\n",
        "  network_1 = Sequential()\n",
        "  network_1.add(Dense(units = 4, input_dim=X_train.shape[1] ,\n",
        "                      activation='relu', bias_initializer = space['m1_bias_initializer1'],\n",
        "                      kernel_initializer=space['m1_kernel_initializer1']))\n",
        "  \n",
        "  network_1.add(Dense(units = 4, activation='relu',\n",
        "                      bias_initializer = space['m1_bias_initializer2'],\n",
        "                      kernel_initializer = space['m1_kernel_initializer2']))\n",
        "  network_1.add(Dropout(space['m1_dropout']))\n",
        "  network_1.add(Dense(units = 4, activation='relu'))\n",
        "  network_1.add(Dense(units = 4, activation='relu'))\n",
        "  \n",
        "  # Network 2\n",
        "  network_2 = Sequential()\n",
        "  network_2.add(Dense(units = 16, input_dim=X_train.shape[1] , activation='relu',\n",
        "                      bias_initializer = space['m2_bias_initializer1'],\n",
        "                      kernel_initializer=space['m2_kernel_initializer1']))\n",
        "  if space['batch_normalisation']:\n",
        "        network_2.add(BatchNormalization())\n",
        "  network_2.add(Dense(units = 16, activation='relu'))\n",
        "  network_2.add(Dropout(space['m2_dropout']))\n",
        "  \n",
        "  combinedInput = concatenate([network_1.output, network_2.output])\n",
        "  x = Dense(1, activation=\"linear\")(combinedInput)\n",
        "  model = Model(inputs=[network_1.input, network_2.input], outputs=x)\n",
        "  adam = Adam(learning_rate=space['lr']) \n",
        "  model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mean_squared_error'])\n",
        "  \n",
        "  history = model.fit( x=[X_train, X_train],\n",
        "          y=y_train,\n",
        "          validation_split = 0.2,\n",
        "          epochs=space['epochs'], batch_size=space['batch_size'], verbose = 0)\n",
        "  # Can add connections to Tensorboard , Loss Curves and Report Generation\n",
        "  \n",
        "  return (history , model)"
      ],
      "metadata": {
        "id": "xqHaA2QBQWns"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tune_dnn(space):\n",
        "    \n",
        "    sched = AsyncHyperBandScheduler(time_attr=\"training_iteration\", max_t=10000, grace_period=100)\n",
        "    search_alg = HyperOptSearch(space , metric = \"mean_se\", mode = 'min')\n",
        "    search_alg = ConcurrencyLimiter(search_alg, max_concurrent = 15)\n",
        "\n",
        "    analysis = tune.run(hyper_tuner, search_alg = search_alg,\n",
        "                        config = space, metric = 'mean_se',\n",
        "                        mode = 'min',scheduler=sched, verbose = 1,\n",
        "                        num_samples = 2, resources_per_trial={\"cpu\": os.cpu_count()})  # -1 sometimes\n",
        "    \n",
        "    history,model = tuned_dnn(analysis.best_config)\n",
        "    return model, analysis"
      ],
      "metadata": {
        "id": "zO_qc3rQQHmZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "W_7Toct98f7i"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, analysis = tune_dnn(space)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "ANcgn-C8LXGP",
        "outputId": "2298a0fa-a49a-4ae1-ab6c-32a09a6a9930"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-06-17 09:16:48 (running for 00:00:33.30)<br>Memory usage on this node: 1.7/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 6400.000: None | Iter 1600.000: None | Iter 400.000: None | Iter 100.000: None<br>Resources requested: 0/2 CPUs, 0/0 GPUs, 0.0/7.35 GiB heap, 0.0/3.67 GiB objects<br>Current best trial: 23af0244 with mean_se=298.8730773925781 and parameters={'m1_kernel_initializer1': 'he_normal', 'm1_bias_initializer1': 'ones', 'm1_kernel_initializer2': 'he_uniform', 'm1_bias_initializer2': 'ones', 'm1_dropout': 0.25, 'm2_kernel_initializer1': 'glorot_normal', 'm2_bias_initializer1': 'ones', 'batch_normalisation': None, 'm2_dropout': 0, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}<br>Result logdir: /root/ray_results/hyper_tuner_2022-06-17_09-16-15<br>Number of trials: 2/2 (2 TERMINATED)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-17 09:16:49,079\tINFO tune.py:748 -- Total run time: 33.53 seconds (33.27 seconds for the tuning loop).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis.best_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED7ru0Ht82E0",
        "outputId": "16276dbd-0e63-4fe8-e28c-f66216f43ba9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_normalisation': None,\n",
              " 'batch_size': 32,\n",
              " 'epochs': 10,\n",
              " 'lr': 0.001,\n",
              " 'm1_bias_initializer1': 'ones',\n",
              " 'm1_bias_initializer2': 'ones',\n",
              " 'm1_dropout': 0.25,\n",
              " 'm1_kernel_initializer1': 'he_normal',\n",
              " 'm1_kernel_initializer2': 'he_uniform',\n",
              " 'm2_bias_initializer1': 'ones',\n",
              " 'm2_dropout': 0,\n",
              " 'm2_kernel_initializer1': 'glorot_normal'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([X_test, X_test])"
      ],
      "metadata": {
        "id": "iVnqCY3Kmnxw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO24zJIR9EbN",
        "outputId": "cf498b50-4593-4413-cdb1-871d6a111966"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.7856823],\n",
              "       [2.0177858],\n",
              "       [2.7519245],\n",
              "       ...,\n",
              "       [1.7425326],\n",
              "       [1.6950011],\n",
              "       [2.2255912]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}